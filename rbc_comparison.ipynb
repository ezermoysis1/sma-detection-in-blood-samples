{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file I am \n",
    "- Loading a pre-trained and saved model\n",
    "- Passing all RBC images from an input directory one by one to the model, which classifies all images as non-sma / sma\n",
    "- Demonstrate 20 most certain non-sma vs. 20 most certain SMA classified RBC images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from my_models import my_ResNet_CNN\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "transform_simple = transforms.Compose([\n",
    "            transforms.Resize((128, 128)),  # resize to 64x64\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "class RedCellMorphologyDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((128, 128)),  # resize to 64x64\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        for label, class_name in enumerate(['non-sma', 'sma']):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            for subfolder_name in os.listdir(class_dir):\n",
    "                subfolder_dir = os.path.join(class_dir, subfolder_name)\n",
    "                for filename in os.listdir(subfolder_dir):\n",
    "                    if filename.endswith(\".png\"):  # Or whatever format your images are in\n",
    "                        self.image_paths.append(os.path.join(subfolder_dir, filename))\n",
    "                        self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\") \n",
    "        img = transform_simple(img)  # Apply the transform\n",
    "        return img.unsqueeze(0), label, img_path  # Add the extra batch dimension here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RedCellMorphologyDataset('RCM_binary_cells_clean_no_severe_moderate_mild_20filter (copy)')\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)  # shuffle=False to keep track of the original order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset: 12212\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of the dataset: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that the model is a binary classifier with a sigmoid function in its last layer\n",
    "model = my_ResNet_CNN()\n",
    "model.load_state_dict(torch.load('Experiments_log/20230805_051103/model_weights_4.pth'))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "data = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels, img_paths in dataloader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(imgs, mode='test')\n",
    "        probs = outputs.cpu().numpy()\n",
    "        for img_path, label, prob in zip(img_paths, labels, probs):\n",
    "            data.append([img_path, label.item(), prob[0]])\n",
    "\n",
    "df = pd.DataFrame(data, columns=['image_path', 'true_label', 'predicted_probability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame\n",
    "df = df.sort_values(by='predicted_probability')\n",
    "\n",
    "# Get image paths\n",
    "lowest_20 = df['image_path'].head(200).values\n",
    "highest_20 = df['image_path'].tail(200).values\n",
    "\n",
    "print(type(highest_20))\n",
    "print(highest_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a mask where 'predicted probability' is close to 0.9\n",
    "#mask = (df['predicted_probability'] < 0.25) & (df['predicted_probability'] > 0.12)\n",
    "\n",
    "## use the mask to filter rows\n",
    "#filtered_df = df[mask]\n",
    "#print(len(filtered_df))\n",
    "\n",
    "\n",
    "## get the 'image_path' column values from the filtered dataframe\n",
    "#lowest_20 = filtered_df['image_path'].head(20).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a mask where 'predicted probability' is close to 0.9\n",
    "#mask = (df['predicted_probability'] < 0.97) & (df['predicted_probability'] > 0.94)\n",
    "\n",
    "## use the mask to filter rows\n",
    "#filtered_df = df[mask]\n",
    "#print(len(filtered_df))\n",
    "\n",
    "\n",
    "## get the 'image_path' column values from the filtered dataframe\n",
    "#highest_20 = filtered_df['image_path'].head(20).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of rows and columns for the grid\n",
    "nrows = int(np.round(len(highest_20) / 4))\n",
    "ncols = 4\n",
    "\n",
    "fig, ax = plt.subplots(nrows, ncols*2, figsize=(10, 50))  # change ncols to ncols*2 and adjust figsize\n",
    "\n",
    "# Add title\n",
    "fig.suptitle('Red Blood Cells Comparison', fontsize=20)\n",
    "\n",
    "# plot 'Non-sma Red Blood Cells'\n",
    "for i, image_path in enumerate(lowest_20):\n",
    "    img = Image.open(image_path)\n",
    "    img_array = np.array(img)\n",
    "    ax[i//ncols, i%ncols].imshow(img_array)\n",
    "    ax[i//ncols, i%ncols].axis('off')  # to remove the axis\n",
    "    # if i < ncols:\n",
    "    #     ax[0, i].set_title('non-sma')  # add subtitle to the first row of 'non-sma' images\n",
    "\n",
    "# If the total number of 'Non-sma' images is less than nrows*ncols\n",
    "for i in range(len(lowest_20), nrows*ncols):\n",
    "    ax[i//ncols, i%ncols].axis('off')  # to remove the empty plots\n",
    "\n",
    "# plot 'sma Red Blood Cells'\n",
    "for i, image_path in enumerate(highest_20):\n",
    "    img = Image.open(image_path)\n",
    "    img_array = np.array(img)\n",
    "    ax[i//ncols, i%ncols + ncols].imshow(img_array)  # add ncols to the column index for right side plotting\n",
    "    ax[i//ncols, i%ncols + ncols].axis('off')  # to remove the axis\n",
    "    # if i < ncols:\n",
    "    #     ax[0, i + ncols].set_title('sma')  # add subtitle to the first row of 'sma' images\n",
    "\n",
    "# If the total number of 'sma' images is less than nrows*ncols\n",
    "for i in range(len(highest_20), nrows*ncols):\n",
    "    ax[i//ncols, i%ncols + ncols].axis('off')  # to remove the empty plots\n",
    "\n",
    "# Add a black line between columns 4 and 5, shift the line a little bit to the right, and make it shorter\n",
    "line_x = (ax[0, ncols-1].get_position().bounds[0] + ax[0, ncols].get_position().bounds[0]) / 2\n",
    "offset = 0.03  # change this value to move the line more or less\n",
    "lower_bound = 0.03  # adjust this value to control the lower bound of the line\n",
    "upper_bound = 0.90  # adjust this value to control the upper bound of the line\n",
    "plt.plot([line_x + offset, line_x + offset], [lower_bound, upper_bound], color='black', transform=plt.gcf().transFigure, clip_on=False, lw=1)\n",
    "\n",
    "# add more space between the 4th and 5th columns\n",
    "fig.subplots_adjust(wspace=0.3)\n",
    "\n",
    "# Add subtitles for the two groups of columns\n",
    "x_position_1 = (ax[0, 0].get_position().bounds[0] + ax[0, ncols-1].get_position().bounds[0] + ax[0, ncols-1].get_position().bounds[2]) / 2 -0.06\n",
    "x_position_2 = (ax[0, ncols].get_position().bounds[0] + ax[0, ncols*2-1].get_position().bounds[0] + ax[0, ncols*2-1].get_position().bounds[2]) / 2 + 0.035\n",
    "y_position = ax[0, 0].get_position().bounds[1] + ax[0, 0].get_position().bounds[3] +0.03\n",
    "fig.text(x_position_1, y_position, 'non-sma', ha='center', va='bottom', fontsize=14)\n",
    "fig.text(x_position_2, y_position, 'sma', ha='center', va='bottom', fontsize=14)\n",
    "\n",
    "plt.tight_layout()  # added to avoid overlapping of titles and images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage import io, measure, filters, color\n",
    "\n",
    "\n",
    "def get_descriptors_dataframe(image_paths):\n",
    "    # Initialize an empty list to store each image's descriptor dictionary\n",
    "    all_descriptors = []\n",
    "\n",
    "    fig, axs = plt.subplots(5, 4, figsize=(15, 15))\n",
    "    axs = axs.ravel()\n",
    "\n",
    "    for idx, image_path in enumerate(image_paths):\n",
    "        # Check if the file exists\n",
    "        if not os.path.isfile(image_path):\n",
    "            print(f\"File {image_path} not found.\")\n",
    "            continue\n",
    "\n",
    "        # Read the image\n",
    "        image = io.imread(image_path)\n",
    "\n",
    "        # If the image is not grayscale, convert it to grayscale\n",
    "        if len(image.shape) > 2:\n",
    "            gray_image = color.rgb2gray(image)\n",
    "\n",
    "        # Threshold the image to get a binary image\n",
    "        threshold_value = filters.threshold_otsu(gray_image)\n",
    "        binary_image = gray_image < threshold_value\n",
    "\n",
    "        # Label the image\n",
    "        label_image = measure.label(binary_image)\n",
    "\n",
    "        # Use regionprops to get the descriptors\n",
    "        regions = measure.regionprops(label_image, intensity_image=gray_image)\n",
    "        # Select the region with the largest area\n",
    "        region = max(regions, key=lambda region: region.area)\n",
    "\n",
    "        # For simplicity, we take the descriptors of the first region.\n",
    "        if regions:\n",
    "            props = region\n",
    "            descriptor_dict = {\n",
    "                'area': props.area,\n",
    "                'mean_intensity': props.mean_intensity,\n",
    "                'eccentricity': props.eccentricity,\n",
    "                'convex_area': props.convex_area,\n",
    "                'extent': props.extent,\n",
    "                'solidity': props.solidity,\n",
    "                'perimeter': props.perimeter,\n",
    "                'orientation': props.orientation,\n",
    "                'perimeter_crofton': props.perimeter_crofton\n",
    "            }\n",
    "            # Draw a rectangle around the chosen region\n",
    "            minr, minc, maxr, maxc = props.bbox\n",
    "            rect = patches.Rectangle((minc, minr), maxc - minc, maxr - minr, fill=False, edgecolor='red', linewidth=2)\n",
    "            axs[idx].imshow(image)\n",
    "            axs[idx].add_patch(rect)\n",
    "\n",
    "            # Extract the relevant part of the image path\n",
    "            title = image_path\n",
    "            title = title[title.index('sma'):] if 'sma' in title else title[title.index('non-sma'):]\n",
    "\n",
    "            axs[idx].set_title(f\"Region from {title}\")\n",
    "            axs[idx].axis('off')\n",
    "        else:\n",
    "            descriptor_dict = {\n",
    "                'area': None,\n",
    "                'mean_intensity': None,\n",
    "                'eccentricity': None,\n",
    "                'convex_area': None,\n",
    "                'extent': None,\n",
    "                'solidity': None,\n",
    "                'perimeter': None,\n",
    "                'orientation': None,\n",
    "                'perimeter_crofton': None\n",
    "\n",
    "            }\n",
    "\n",
    "        # Add the image path to the dictionary\n",
    "        descriptor_dict['image_path'] = image_path\n",
    "\n",
    "        # Add this dictionary to the list\n",
    "        all_descriptors.append(descriptor_dict)\n",
    "\n",
    "        # After visualizing 20 images, break the loop\n",
    "        if idx >= 19:\n",
    "            break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Convert the list of dictionaries into a DataFrame\n",
    "    df = pd.DataFrame(all_descriptors)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_highest = get_descriptors_dataframe(highest_20)\n",
    "descriptors_lowest = get_descriptors_dataframe(lowest_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_lowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns with numeric data\n",
    "descriptors_numeric_highest = descriptors_highest.select_dtypes(include=[np.number])\n",
    "descriptors_numeric_lowest = descriptors_lowest.select_dtypes(include=[np.number])\n",
    "\n",
    "# descriptors_numeric_highest = descriptors_highest\n",
    "# descriptors_numeric_lowest = descriptors_lowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_numeric_highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "def compare_dataframes(df1, df2):\n",
    "    # Add an extra column 'Source' for identification\n",
    "    df1['Source'] = 'SMA'\n",
    "    df2['Source'] = 'Non-SMA'\n",
    "\n",
    "    # Concatenate the dataframes\n",
    "    df = pd.concat([df1, df2])\n",
    "\n",
    "    # Reshape the dataframe suitable for sns.boxplot\n",
    "    df_melt = df.melt(id_vars='Source')\n",
    "\n",
    "    # Get the unique column names (variables)\n",
    "    columns = df_melt['variable'].unique()\n",
    "    n_columns = len(columns)\n",
    "\n",
    "    # Calculate the number of rows and columns for the subplots\n",
    "    nrows = 3 # 2 columns of subplots\n",
    "    ncols = 3\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(14, 4*nrows))\n",
    "    \n",
    "    if n_columns == 1:\n",
    "        axes = [axes]  # if only one subplot, axes is not an array, this line takes care of that \n",
    "\n",
    "    for ax, col in zip(axes.flatten(), columns):\n",
    "        print(col)\n",
    "        # Create a subset of the data for the current column\n",
    "        subset = df_melt[df_melt['variable'] == col]\n",
    "        \n",
    "        # T-test\n",
    "        group1 = subset[subset['Source'] == 'SMA']['value']\n",
    "        group2 = subset[subset['Source'] == 'Non-SMA']['value']\n",
    "        t_stat, p_val = stats.ttest_ind(group1, group2)\n",
    "\n",
    "        # Create a subplot for each column\n",
    "        sns.boxplot(x='variable', y='value', hue='Source', data=subset, ax=ax, palette='PRGn')\n",
    "        ax.set_title(f\"{col} (p-value: {p_val:.2e})\")  # 2 decimal places in scientific notation\n",
    "\n",
    "    # if there are more axes than columns, delete the extra ones\n",
    "    for i in range(n_columns, nrows*ncols):\n",
    "        fig.delaxes(axes.flatten()[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "compare_dataframes(descriptors_numeric_highest, descriptors_numeric_lowest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EzerM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

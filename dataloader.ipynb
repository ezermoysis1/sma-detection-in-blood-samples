{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Pytorch dataset object that loads MNIST dataset as bags.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import DatasetFolder\n",
    "from torchvision.io import read_image\n",
    "import os\n",
    "\n",
    "def loader(path: str) -> torch.Tensor:\n",
    "    return read_image(path)\n",
    "\n",
    "class MyNestedFolderDataset(DatasetFolder):\n",
    "    def __init__(self, root='/Users/ezermoysis/Documents/UCL/Year end project/Malaria/Malaria-Detection-in-Blood-Samples/Red_Cell_Morphology/sma_edof', target_folders=None, transform=None, target_transform=None):\n",
    "        print('here5')\n",
    "\n",
    "        super(MyNestedFolderDataset, self).__init__(root, loader, extensions='tiff', transform=transform,\n",
    "                                                    target_transform=target_transform)\n",
    "        \n",
    "        self.target_folders = target_folders if target_folders is not None else []\n",
    "\n",
    "        self.samples = self._find_samples_in_subfolders()\n",
    "\n",
    "    def _find_samples_in_subfolders(self):\n",
    "        samples = []\n",
    "        classes = sorted(entry.name for entry in os.scandir(self.root) if entry.is_dir())\n",
    "        print(classes)\n",
    "        class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "        for class_name in classes:\n",
    "            class_dir = os.path.join(self.root, class_name)\n",
    "            for subfolder in os.scandir(class_dir):\n",
    "                if subfolder.is_dir():\n",
    "                    for target in os.scandir(subfolder):\n",
    "                        if target.is_file() and target.name.endswith(self.extensions):\n",
    "                            item = (target.path, class_to_idx[class_name])\n",
    "                            samples.append(item)\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBags(data_utils.Dataset):\n",
    "    def __init__(self, root='Red_Cell_Morphology', target_folders=None, target_number=1, seed=1, train=True):\n",
    "        self.root = root\n",
    "        self.target_folders=target_folders\n",
    "        self.target_number = target_number\n",
    "        self.train = train\n",
    "        print('here2')\n",
    "\n",
    "        self.r = np.random.RandomState(seed)\n",
    "\n",
    "        if self.train:\n",
    "            self.train_bags_list, self.train_labels_list = self._create_bags()\n",
    "        else:\n",
    "            self.test_bags_list, self.test_labels_list = self._create_bags()\n",
    "\n",
    "    def _create_bags(self):\n",
    "        print('here3')\n",
    "\n",
    "        data_transform = transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  # Change normalization parameters as per your dataset\n",
    "        print('here4')\n",
    "\n",
    "        dataset = MyNestedFolderDataset(root=self.root, target_folders=self.target_folders, transform=data_transform)\n",
    "        loader = data_utils.DataLoader(dataset, batch_size=self.num_in_train if self.train else self.num_in_test, shuffle=False)\n",
    "        print('here6')\n",
    "\n",
    "        for (batch_data, batch_labels) in loader:\n",
    "            all_imgs = batch_data\n",
    "            all_labels = batch_labels\n",
    "\n",
    "        bags_list = []\n",
    "        labels_list = []\n",
    "\n",
    "        for i in range(self.num_bag):\n",
    "            bag_length = np.int(self.r.normal(self.mean_bag_length, self.var_bag_length, 1))\n",
    "            if bag_length < 1:\n",
    "                bag_length = 1\n",
    "\n",
    "            if self.train:\n",
    "                indices = torch.LongTensor(self.r.randint(0, self.num_in_train, bag_length))\n",
    "            else:\n",
    "                indices = torch.LongTensor(self.r.randint(0, self.num_in_test, bag_length))\n",
    "\n",
    "            labels_in_bag = all_labels[indices]\n",
    "            labels_in_bag = labels_in_bag == self.target_number\n",
    "\n",
    "            bags_list.append(all_imgs[indices])\n",
    "            labels_list.append(labels_in_bag)\n",
    "\n",
    "        return bags_list, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here2\n",
      "here3\n",
      "here4\n",
      "here5\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Found no valid file for the classes SMA_cells. Supported extensions are: tiff",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mhere\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     train_loader \u001b[39m=\u001b[39m data_utils\u001b[39m.\u001b[39mDataLoader(MyBags(root\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mRed_Cell_Morphology\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m                                                 target_folders\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39msma_edof\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mnonsickle-edofed\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      8\u001b[0m                                                 target_number\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m                                                 seed\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m                                                 train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m),\n\u001b[1;32m     11\u001b[0m                                          batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     12\u001b[0m                                          shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mhere\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m     len_bag_list_train \u001b[39m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[54], line 12\u001b[0m, in \u001b[0;36mMyBags.__init__\u001b[0;34m(self, root, target_folders, target_number, seed, train)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mRandomState(seed)\n\u001b[1;32m     11\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_bags_list, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_labels_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_bags()\n\u001b[1;32m     13\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_bags_list, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_labels_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_bags()\n",
      "Cell \u001b[0;32mIn[54], line 24\u001b[0m, in \u001b[0;36mMyBags._create_bags\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m data_transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([\n\u001b[1;32m     20\u001b[0m                        transforms\u001b[39m.\u001b[39mToTensor(),\n\u001b[1;32m     21\u001b[0m                        transforms\u001b[39m.\u001b[39mNormalize((\u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m), (\u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m))])  \u001b[39m# Change normalization parameters as per your dataset\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mhere4\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m dataset \u001b[39m=\u001b[39m MyNestedFolderDataset(root\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot, target_folders\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_folders, transform\u001b[39m=\u001b[39;49mdata_transform)\n\u001b[1;32m     25\u001b[0m loader \u001b[39m=\u001b[39m data_utils\u001b[39m.\u001b[39mDataLoader(dataset, batch_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_in_train \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_in_test, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     26\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mhere6\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[53], line 12\u001b[0m, in \u001b[0;36mMyNestedFolderDataset.__init__\u001b[0;34m(self, root, target_folders, transform, target_transform)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, root\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/Users/ezermoysis/Documents/UCL/Year end project/Malaria/Malaria-Detection-in-Blood-Samples/Red_Cell_Morphology/sma_edof\u001b[39m\u001b[39m'\u001b[39m, target_folders\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, transform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, target_transform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mhere5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m     \u001b[39msuper\u001b[39;49m(MyNestedFolderDataset, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root, loader, extensions\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtiff\u001b[39;49m\u001b[39m'\u001b[39;49m, transform\u001b[39m=\u001b[39;49mtransform,\n\u001b[1;32m     13\u001b[0m                                                 target_transform\u001b[39m=\u001b[39;49mtarget_transform)\n\u001b[1;32m     15\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_folders \u001b[39m=\u001b[39m target_folders \u001b[39mif\u001b[39;00m target_folders \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m []\n\u001b[1;32m     17\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msamples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_find_samples_in_subfolders()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/FYPenv/lib/python3.11/site-packages/torchvision/datasets/folder.py:145\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(root, transform\u001b[39m=\u001b[39mtransform, target_transform\u001b[39m=\u001b[39mtarget_transform)\n\u001b[1;32m    144\u001b[0m classes, class_to_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfind_classes(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot)\n\u001b[0;32m--> 145\u001b[0m samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_dataset(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot, class_to_idx, extensions, is_valid_file)\n\u001b[1;32m    147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader \u001b[39m=\u001b[39m loader\n\u001b[1;32m    148\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextensions \u001b[39m=\u001b[39m extensions\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/FYPenv/lib/python3.11/site-packages/torchvision/datasets/folder.py:189\u001b[0m, in \u001b[0;36mDatasetFolder.make_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39mif\u001b[39;00m class_to_idx \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[39m# prevent potential bug since make_dataset() would use the class_to_idx logic of the\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     \u001b[39m# find_classes() function, instead of using that of the find_classes() method, which\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     \u001b[39m# is potentially overridden and thus could have a different logic.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe class_to_idx parameter cannot be None.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 189\u001b[0m \u001b[39mreturn\u001b[39;00m make_dataset(directory, class_to_idx, extensions\u001b[39m=\u001b[39;49mextensions, is_valid_file\u001b[39m=\u001b[39;49mis_valid_file)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/FYPenv/lib/python3.11/site-packages/torchvision/datasets/folder.py:102\u001b[0m, in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[39mif\u001b[39;00m extensions \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m         msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSupported extensions are: \u001b[39m\u001b[39m{\u001b[39;00mextensions\u001b[39m \u001b[39m\u001b[39mif\u001b[39;00m\u001b[39m \u001b[39m\u001b[39misinstance\u001b[39m(extensions,\u001b[39m \u001b[39m\u001b[39mstr\u001b[39m)\u001b[39m \u001b[39m\u001b[39melse\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(extensions)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(msg)\n\u001b[1;32m    104\u001b[0m \u001b[39mreturn\u001b[39;00m instances\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Found no valid file for the classes SMA_cells. Supported extensions are: tiff"
     ]
    }
   ],
   "source": [
    "__name__='__main__'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print('here')\n",
    "    train_loader = data_utils.DataLoader(MyBags(root='Red_Cell_Morphology',\n",
    "                                                target_folders=['sma_edof', 'nonsickle-edofed'],\n",
    "                                                target_number=1,\n",
    "                                                seed=1,\n",
    "                                                train=True),\n",
    "                                         batch_size=1,\n",
    "                                         shuffle=True)\n",
    "\n",
    "    print('here')\n",
    "\n",
    "    len_bag_list_train = []\n",
    "    mnist_bags_train = 0\n",
    "    for batch_idx, (bag, label) in enumerate(train_loader):\n",
    "        len_bag_list_train.append(int(bag.squeeze(0).size()[0]))\n",
    "        mnist_bags_train += label[0].numpy()[0]\n",
    "    print('Number positive train bags: {}/{}\\n'\n",
    "          'Number of instances per bag, mean: {}, max: {}, min {}\\n'.format(\n",
    "        mnist_bags_train, len(train_loader),\n",
    "        np.mean(len_bag_list_train), np.max(len_bag_list_train), np.min(len_bag_list_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYPenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
